{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMLQKYMPZP/UsgiKLUMP/PS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d0k7/Pattern-Recognition-Machine-Learning-Lab-Code/blob/main/PR_%26_ML_LAB_CODE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1) Data pre-processing using Python Machine Learning libraries/ MATLAB."
      ],
      "metadata": {
        "id": "gZaw7V2Vz5dh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Importing dataset\n",
        "dataset = pd.read_csv('/content/Data.csv')\n",
        "x = dataset.iloc[:, :-1].values  # Independent variable matrix\n",
        "y = dataset.iloc[:, 3].values     # Dependent vector variable\n",
        "\n",
        "print(x)\n",
        "print(y)\n",
        "\n",
        "\n",
        "\n",
        "#Handling missing data\n",
        "# Using SimpleImputer to handle missing values\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "imputer = SimpleImputer(strategy='mean')  # Automatically handles NaN values\n",
        "\n",
        "# Fit the imputer to the columns with missing values (columns 1 and 2)\n",
        "imputer = imputer.fit(x[:, 1:3])\n",
        "\n",
        "# Transform the dataset by replacing missing values with the mean of respective columns\n",
        "x[:, 1:3] = imputer.transform(x[:, 1:3])\n",
        "\n",
        "print(x)\n",
        "\n",
        "\n",
        "\n",
        "#Encoding categoricaal data\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "labelencoder_x=LabelEncoder()\n",
        "x[:,0]=labelencoder_x.fit_transform(x[:,0])\n",
        "print(x[:,0])\n",
        "\n",
        "# Define the ColumnTransformer\n",
        "column_transformer = ColumnTransformer(\n",
        "    transformers=[('encoder', OneHotEncoder(), [0])],  # Apply OneHotEncoder to the first column\n",
        "    remainder='passthrough'  # Keep the remaining columns unchanged\n",
        ")\n",
        "\n",
        "x = column_transformer.fit_transform(x)\n",
        "\n",
        "print(x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Label encoding the dependent variable y (if it's categorical)\n",
        "labelencoder_y = LabelEncoder()\n",
        "y = labelencoder_y.fit_transform(y)\n",
        "\n",
        "print(y)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#splitting dataset into traning set and testing set\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test= train_test_split(x,y,test_size=0.2, random_state=0)\n",
        "print(x_train, x_test, y_train, y_test)\n",
        "\n",
        "\n",
        "\n",
        "#feature scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc_x=StandardScaler()\n",
        "x_train=sc_x.fit_transform(x_train)\n",
        "x_test=sc_x.transform(x_test)\n",
        "print(x_train)\n",
        "print(x_test)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xp7Aotny0BV7",
        "outputId": "d7e4f8bb-bc23-475a-a168-01059daad458"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 nan]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' nan 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n",
            "['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n",
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 63777.77777777778]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' 38.77777777777778 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n",
            "[0 2 1 2 1 0 2 0 1 0]\n",
            "[[1.0 0.0 0.0 44.0 72000.0]\n",
            " [0.0 0.0 1.0 27.0 48000.0]\n",
            " [0.0 1.0 0.0 30.0 54000.0]\n",
            " [0.0 0.0 1.0 38.0 61000.0]\n",
            " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
            " [1.0 0.0 0.0 35.0 58000.0]\n",
            " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [1.0 0.0 0.0 48.0 79000.0]\n",
            " [0.0 1.0 0.0 50.0 83000.0]\n",
            " [1.0 0.0 0.0 37.0 67000.0]]\n",
            "[0 1 0 0 1 1 0 1 0 1]\n",
            "[[0.0 1.0 0.0 40.0 63777.77777777778]\n",
            " [1.0 0.0 0.0 37.0 67000.0]\n",
            " [0.0 0.0 1.0 27.0 48000.0]\n",
            " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [1.0 0.0 0.0 48.0 79000.0]\n",
            " [0.0 0.0 1.0 38.0 61000.0]\n",
            " [1.0 0.0 0.0 44.0 72000.0]\n",
            " [1.0 0.0 0.0 35.0 58000.0]] [[0.0 1.0 0.0 30.0 54000.0]\n",
            " [0.0 1.0 0.0 50.0 83000.0]] [1 1 1 0 1 0 0 1] [0 0]\n",
            "[[-1.          2.64575131 -0.77459667  0.26306757  0.12381479]\n",
            " [ 1.         -0.37796447 -0.77459667 -0.25350148  0.46175632]\n",
            " [-1.         -0.37796447  1.29099445 -1.97539832 -1.53093341]\n",
            " [-1.         -0.37796447  1.29099445  0.05261351 -1.11141978]\n",
            " [ 1.         -0.37796447 -0.77459667  1.64058505  1.7202972 ]\n",
            " [-1.         -0.37796447  1.29099445 -0.0813118  -0.16751412]\n",
            " [ 1.         -0.37796447 -0.77459667  0.95182631  0.98614835]\n",
            " [ 1.         -0.37796447 -0.77459667 -0.59788085 -0.48214934]]\n",
            "[[-1.          2.64575131 -0.77459667 -1.45882927 -0.90166297]\n",
            " [-1.          2.64575131 -0.77459667  1.98496442  2.13981082]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2) Design a model to predict the housing price from Boston Dataset using Multivariate Linear Regression."
      ],
      "metadata": {
        "id": "UUTzAZjm1XhN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KVrFiTfS1oe6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}